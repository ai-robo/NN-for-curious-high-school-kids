{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j0ahCAlrbS4"
      },
      "source": [
        "# Классификация изображений элементов одежды с помощью CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXu2w32Mrfwg"
      },
      "source": [
        "В этой части урока мы построим и обучим нейронную сеть классифицировать изображения элементов одежды, такие как платья, кроссовки, рубашки, футболки и т.п. В этом ноутбуке мы снова используем `tf.keras` - высокоуровневый API для построения и тренировки моделей в TensorFlow.\n",
        "\n",
        "Всё впорядке, если какие-то моменты будут не очень понятны."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpKf48bpsWof"
      },
      "source": [
        "## Установка и импорт зависимостей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guqn9YEDsiV1"
      },
      "source": [
        "Нам понадобится **TensorFlow** и несколько вспомогательных библиотек."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QkRNP4jtJkK"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import logging\n",
        "logging.getLogger('tensorflow').disabled = True"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем датасет \"Fashion MNIST\", нормализуем данные. Значение каждого пикселя в изображении находится в интервале [0,255]. Для того, чтобы модель работала корректно эти значения необходимо нормализовать - привести к значениям в интервале [0,1]."
      ],
      "metadata": {
        "id": "YhKifGQU9hco"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12SBKgl5tUNi"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5rb3gIsukAT"
      },
      "source": [
        "##Набор данных Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmTR67o7usYI"
      },
      "source": [
        "В этом примере используется набор данных Fashion MNIST, который содержит 70 000 изображений элементов одежды в 10 категориях в градациях серого. Изображения содержат элементы одежды в низком разрешении (28х28 пикселей), как показано ниже:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zImCoAt4vNOH"
      },
      "source": [
        "![alt text](https://tensorflow.org/images/fashion-mnist-sprite.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHugA8yJvYNy"
      },
      "source": [
        "Fashion MNIST используется как замена классическому набору данных MNIST - чаще всего используется как \"Hello, World!\" в машинном обучении и компьютерном зрении. Набор данных MNIST содержит изображения цифр написанных от руки (0, 1, 2 и тд) в таком же формате, каком представлены элементы одежды в нашем примере."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLy45ekYv26S"
      },
      "source": [
        "В нашем примере мы используем Fashion MNIST из-за разнообразия и потому, что эта задача более интересна с точки зрения реализации, чем решение типичной задачи на наборе данных MNIST. Оба наборы данных достаточно малы, поэтому используются для проверки корректной работоспособности алгоритма. Отличные наборы данных для старта изучения машинного обучения, тестирования и отладки кода."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZJDgFTMwZh5"
      },
      "source": [
        "Мы воспользуемся 60 000 изображениями для тренировки сети и 10 000 изображениями для проверки точности обучения и классификации изображений.\n",
        "\n",
        "Выведем размеры массивов с данными:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-6Q_JyO9TNq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ac601c-1a43-461e-a5a7-a634588b06f4"
      },
      "source": [
        "print(\"Shape of Training Image Data: \" + str(x_train.shape))\n",
        "print(\"Shape of Training Class Data: \" + str(y_train.shape))\n",
        "print(\"Shape of Test Image Data: \" + str(x_test.shape))\n",
        "print(\"Shape of Test Class Data: \" + str(y_test.shape))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Training Image Data: (60000, 28, 28)\n",
            "Shape of Training Class Data: (60000,)\n",
            "Shape of Test Image Data: (10000, 28, 28)\n",
            "Shape of Test Class Data: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD0VmXij96fz"
      },
      "source": [
        "Изображения представляют собой двумерные массивы 28х28, где значения в каждой ячейке могут быть в интервале `[0, 255]`. Метки классов - массив целых чисел, где каждое значение в интервале `[0, 9]`. Эти метки соответствуют выходному классу изображения следующим образом:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Метка</th>\n",
        "    <th>Класс</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>Футболка / топ</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Шорты</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Свитер</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Платье</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Плащ</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Сандали</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Рубашка</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Кроссовок</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Сумка</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Ботинок</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "Каждое изображение относится к одной метке. Так как наименования классов не содержатся в исходном наборе данных, давайте сохраним их для дальнейшего использования, когда будем отрисовывать изображения:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx4F57ay_wy_"
      },
      "source": [
        "class_names = ['Футболка / топ', \"Шорты\", \"Свитер\", \"Платье\",\n",
        "              \"Плащ\", \"Сандали\", \"Рубашка\", \"Кроссовок\", \"Сумка\",\n",
        "              \"Ботинок\"]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtVuOE6Upp_k"
      },
      "source": [
        "### Изучаем данные"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENtNljjJpxSm"
      },
      "source": [
        "Давайте отрисуем какое-нибудь одно изображение, чтобы взглянуть на него:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQzXxHnYp4Ul"
      },
      "source": [
        "# Берём первое изображение.\n",
        "index = 0\n",
        "plt.figure(figsize=(20,16))\n",
        "plt.imshow(x_train[index], cmap=plt.cm.binary)\n",
        "plt.xlabel(class_names[y_train[index]])\n",
        "plt.colorbar()\n",
        "\n",
        "ax = plt.gca()\n",
        "ax.set_xticks(np.arange(-.5, 28, 1))\n",
        "ax.set_yticks(np.arange(-.5, 28, 1))\n",
        "ax.set_xticklabels(np.arange(0, 29, 1))\n",
        "ax.set_yticklabels(np.arange(0, 29, 1))\n",
        "ax.xaxis.tick_top()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST6duHs4rL9_"
      },
      "source": [
        "Отобразим первые 25 изображений из тренировочного набора данных и под каждым изображением укажем к какому классу оно относится.\n",
        "\n",
        "Убедитесь, что данные в корректном формате и мы готовы приступить к созданию и обучению сети."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[y_train[i]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oFr5Z7DdOq1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NhM4XZvswNG"
      },
      "source": [
        "### Строим модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiG0VXLds0xZ"
      },
      "source": [
        "Построение нейронной сети требует настройки слоёв, а затем сборки модели с функциями оптимизации и потерь."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk_rjzLMtAvC"
      },
      "source": [
        "###Настраиваем слои"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xGhqpT2tDpx"
      },
      "source": [
        "Базовым элементом при построении нейронной сети является *слой*. Слой извлекает представление из данных, которые поступили ему на вход."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z73tLX7ftoeY"
      },
      "source": [
        "Большую часть времени занимаясь глубоким обучением вы будете заниматься созданием связей между слоями. Большинство слоёв, например, такие как `tf.keras.layers.Dense` имеют набор параметров, которые могут быть \"подогнаны\" во время процесса обучения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SeDUuIiuDSF"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    # Ниже для слоя Conv2D используется 32 фильтра с ядрами 3х3 пикселя каждый. Параметр padding=’same’ означает,\n",
        "    # что выходная карта признаков на каждом канале должна быть той же размерностью, что и исходное изображение,\n",
        "    # т.е. 28х28 элементов. Фактически, это означает добавление значений на границах двумерных данных (обычно нулей),\n",
        "    # чтобы центр ядра фильтра мог размещаться над граничными элементами, используется функция активации ReLu\n",
        "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,\n",
        "                           input_shape=(28, 28, 1)),\n",
        "    # Следующий слой должен укрупнять масштаб полученных признаков. Для этого чаще всего используется операция MaxPooling.\n",
        "    # Здесь pool_size (2, 2) - размер окна, в котором выбирается максимальное значение; strides – шаг сканирования по координатам плоскости\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
        "    # Снова слой Conv2D, но уже используется 64 фильтра\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),\n",
        "    # Снова слой MaxPooling2D\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STf6vl-FuS-M"
      },
      "source": [
        "**ВЫходная часть сети состоит из трёх слоёв:**\n",
        "\n",
        "* `tf.keras.layers.Flatten` - этот слой преобразует изображения размером 28х28 пикселей в 1D-массив размером 784 (28 * 28). На этом слое у нас нет никаких параметров для обучения, так как этот слой занимается только преобразованием входных данных.\n",
        "\n",
        "* **скрытый слой** `tf.keras.layers.Dense` - плотносвязный слой из 128 нейронов. Каждый нейрон (узел) принимает на вход все 784 значения с предыдущего слоя, изменяет входные значения согласно внутренним весам и смещениям во время тренировки и возвращает единственное значение на следующий слой.\n",
        "\n",
        "* **выходной слой** `ts.keras.layers.Dense` - `softmax`-слой состоит из 10 нейронов, каждый из которых представляет определённый класс элемента одежды. Как и в предыдущем слое, каждый нейрон принимает на вход значения всех 128 нейронов предыдущего слоя. Веса и смещения каждого нейрона на этом слое изменяются при обучении таким образом, чтобы результатирующее значение было в интервале `[0,1]` и представляло собой вероятность того, что изображение относится  к этому классу. Сумма всех выходных значений 10 нейронов равна 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7uhttnf8IjQ"
      },
      "source": [
        "###Компилируем модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2qxtG238QTD"
      },
      "source": [
        "Перед тем как мы приступим к обучению модели, стоит ещё выполнить несколько настроек. Эти настройки производятся во время сборки модели при вызове метода `compile`:\n",
        "\n",
        "* *функция потерь* - алгоритм измерения того, насколько далеко находится желаемое значение от спрогнозированного.\n",
        "* *функция оптимизации* - агоритм \"подгонки\" внутренних параметров (весов и смещений) модели для минимизации функции потерь;\n",
        "* *метрики* - используются для мониторинга процесса тренировки и тестирования. Пример ниже использует такую метрику как `точность`, процент изображений, которые были корректно классифицированы."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLk3wbws-msS"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Визуализируем модель"
      ],
      "metadata": {
        "id": "ipBiVIv2DmDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "pViBjKv3D1gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False)"
      ],
      "metadata": {
        "id": "gdPaCBJED62Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNCNQ1lS-v5Y"
      },
      "source": [
        "## Обучаем модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEil-fKj-x9h"
      },
      "source": [
        "Модель учится сопоставлять входное изображение с меткой класса.\n",
        "Параметр `epochs=10` ограничивает количество эпох обучения до 10 полных обучающих итераций по набору данных, что в итоге даёт нам тренировку на 10 * 60000 = 600 000 примерах.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwCq5d-7GATN"
      },
      "source": [
        "# Добавляем пустое цветовое измерение, так как сверточная сеть требует этого.\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "history = model.fit(\n",
        "\n",
        "      # Данные для обучения: изображения и их классы.\n",
        "      x_train, y_train,\n",
        "\n",
        "      # размер батча\n",
        "      batch_size=64,\n",
        "\n",
        "      # количество эпох обучения\n",
        "      epochs=10,\n",
        "\n",
        "      # Модель выделит часть обучающих данных (20%) и не будет на ней обучаться,\n",
        "      # а будет оценивать ошибки модели на основе этих данных в конце каждой эпохи (так называемвя валидация).\n",
        "      validation_split=0.2,\n",
        "\n",
        "      verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n41x8a1fHAK7"
      },
      "source": [
        "В процессе обучения модели значение функции потерь и метрика точности отображаются для каждой обучающей итерации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW6vzdwCHhDe"
      },
      "source": [
        "### Проверяем точность"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7FfGvq6LX_Z"
      },
      "source": [
        "Проверим, какую точность выдаёт модель на тестовых данных. Воспользуемся всеми примерами, которые у нас есть в тестовом наборе данных для проверки точности."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZIVQQt0LwTy"
      },
      "source": [
        "predicted_classes = model.predict(x_test)\n",
        "classes=np.argmax(predicted_classes, axis=1)\n",
        "print(classification_report(y_test, classes, target_names=class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z80-sPlMHge"
      },
      "source": [
        "Как вы можете заметить, точность на тестовом наборе данных оказалась меньше точности на тренировочном наборе данных. Это вполне нормально, так как когда модель обнаруживает изображения, которые она ранее никогда не видела, вполне очевидно, что эффективность классификации снизится. Можете савмостоятельно почитать, что такое **precision, recall** и **f1-score**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PevagOnMojX"
      },
      "source": [
        "## Предсказываем и исследуем"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8FHQzLdMuO_"
      },
      "source": [
        "Посмотрим примеры неправильно классифицированных тестовых данных:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UTKjQbFM-ZA"
      },
      "source": [
        "incorrect = np.nonzero(classes!=y_test)[0]\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "for j, incorrect in enumerate(incorrect[0:8]):\n",
        "    plt.subplot(2, 4, j+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(x_test[incorrect].reshape(28, 28), cmap=\"Reds\")\n",
        "    plt.title(\"Предсказано: {}\".format(class_names[classes[incorrect]]))\n",
        "    plt.xlabel(\"Правильно: {}\".format(class_names[y_test[incorrect]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3pjs3D0TjA8"
      },
      "source": [
        "Воспользуемся обученой моделью, чтобы предсказать метку класса для единственного изображения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gMRY_47TrgB"
      },
      "source": [
        "img = x_test[0]\n",
        "\n",
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54DlnN3UTzOX"
      },
      "source": [
        "Модели в `tf.keras` оптимизированы для предсказаний блоками (коллекциями). Поэтому, несмотря на то, что мы используем единственный элемент необходимо его добавить в список:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMqJq32AUCFI"
      },
      "source": [
        "img = np.array([img])\n",
        "\n",
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzvYFvZsUH3g"
      },
      "source": [
        "Теперь предскажем результат:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kTD8xnaUKSs"
      },
      "source": [
        "predictions_single = model.predict(img)\n",
        "\n",
        "print(predictions_single)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT63WDxlUcvV"
      },
      "source": [
        "Метод `model.predict` возвращает список списков (массив массивов), каждый для изображения из блока входных данных. Получим единственный результат для нашего одного входного изображения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHw2t0eiUtHi"
      },
      "source": [
        "np.argmax(predictions_single[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0et35nwjUyEL"
      },
      "source": [
        "Модель предсказала метку 9 (ботинок)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zma2xWqQU3vX"
      },
      "source": [
        "# Упражнения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2rvAO3_U5iz"
      },
      "source": [
        "Поэкспериментируйте с различными параметрами и посмотрите как будет меняться точность. В частности, попробуйте изменить следующее:\n",
        "\n",
        "* установите параметр `epochs` равным 50;\n",
        "* измените количество нейронов в скрытом слое (слой tf.keras.layers.Dense(128, activation=tf.nn.relu),), например, от низкого значения 32 до 512 и посмотрите, каким образом будет меняться точность прогноза модели;\n",
        "* добавьте дополнительный слой между flatten-слоем (сглаживающим слоем) и конечным dense-слоем, проведите эксперименты с количеством нейронов на этом слое;\n",
        "* не нормализуйте значения пикселей (не делите на 255) и посмотрите, что из этого получится,\n",
        "* поэкспериментируйте с функцией оптимизации - попробуйте вместо adam использовать: adamax, adagrad, nadam...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Выведем карты признаков из сверточного слоя"
      ],
      "metadata": {
        "id": "fEoaJA5a4R_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "По сути, мы здесь копируем часть нашей обученной модели — слоя Conv2D. Затем мы подаем тестовое изображение и визуализируем выходные данные Conv2D — наши карты признаков."
      ],
      "metadata": {
        "id": "boMnxeEX4qoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Слой, который мы хотим скопировать из обученной сверточной сети.\n",
        "layer_name = 'conv2d'\n",
        "\n",
        "# Получаем список слоев из нашей модели\n",
        "layer_dict = {layer.name : layer for layer in model.layers}\n",
        "\n",
        "# Создаем копию существующей модели, содержащую только слой Conv2D.\n",
        "modelslice = tf.keras.Model(inputs=model.inputs, outputs=layer_dict[layer_name].output)\n",
        "\n",
        "# Выбераем изображение (от 0 до 59999) из обучающего набора.\n",
        "image = x_train[0] # Берем первое\n",
        "\n",
        "# Добавляем дополнительное измерение\n",
        "image = np.expand_dims(image, axis=0)\n",
        "\n",
        "# Подаем изображение на вход модели\n",
        "feature_maps = modelslice.predict(image)\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# Мы предполагаем, что у нас есть 32 карты признаков.\n",
        "for i in range(32):\n",
        "    plt.subplot(4,8,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(feature_maps[0, :, :, i-1], cmap=plt.cm.binary)"
      ],
      "metadata": {
        "id": "pKMVM_z95IP0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}